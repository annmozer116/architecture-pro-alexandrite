# Задани 4. Логирование
Сейчас ошибки или нестандартные ситуации разбираются со слов клиента: клиенты рассказывают, как что-то пошло не так. Чтобы понять, что случилось на стороне сервиса, разработчикам и специалистам поддержки требуется очень много времени.
Нужно найти системное решение, которое упростит разбор проблем внутри сервисов и снизит нагрузку поддержки.

## Мотивация
Главная задача логирования - информирование инженеров о том, что происходит в системе. Более полная кратина происходящего поможет в операционных задачах (решение инцидентов) и в стратегических (отслеживание багов, выявление нестандартных кейсов).
Опираясь на проблематику (потеря заказов, зависание заказов), в системе есть набор критических неисправленостей в логике, либо в механизмах обработки. Логирование позволит провести тестирование и отловить эти ошибки.

Улушение операционных процессов работы с инцидентами позволит:
- Снизить время на решение проблем -> 30 min
- Повысить лояльность клиентов

Своевременное отслеживание багов и систематических ошибок позволит:
- Снизить количество ошибок в заказах -> Выполнять больше заказов, Ускорить процесс выполнения заказов 
- Повысить лояльность клиентов, уменьшить отток к конкурентам
- Снизить количество негативных отзывов
- Снизить процент отмененных заказов
- оптимизировать бизнес процессы (подробное логирование позвоит лучше понять эффективность работы с заказами на разных этапах)


# Предлагаемое решение
Приоритет компонентов для логирования и трейсинга:
- MES API: ядро бизнеса, может являться основным источником ошибок и имеет основное влияние на производственный процесс
- CRM API: логирование позволит отслеживать бОльшее количество статусов производства
- RabbitMQ: проблема потерь заказов может быть связана со сбоями очереди
- Shop API: обратить внимание на логирование при появлении "пользвоательских" проблем (не создается заказ, не отображается список заказов и т.д)
- Фронтенды: наименьший приоритет для анализа пользовательского взаимодействия и отлавливания интерфейсных ошибок

## Архитектура
Ядро стека: OpenTelemetry (OTel) как единый стандарт.

- Бэкенды (Shop API, CRM API, MES API): подключение OTel SDK
- Фронтенды (Vue/React): OTel JS для сбора ошибок и навигационных событий. Может быть избыточно
- Сбор и экспорт: OTel Collector как единый агент на каждом поде
- Экспорт логов в: Loki (дешевле чем Elastic), Jaeger (для трейсов), Prometeus (для метрик)
- Визуализация и алертинг: Grafana (дашборды поверх логов из Loki и трейсов из Jaeger, там же метрики от Prometeus) (описано в рамках решения по мониторингу).

## Общие принципы логирования
- Структурированные логи в JSON.
- Обязательные поля для трассировки: trace_id, span_id, service.name, service.version 
- Бизнес-идентификаторы: order_id, customer_id (хэшированный) везде, где применимо, event_name
- Ключевые события для логирования: изменение статуса заказа, запуск и окончание расчета стоимости, API вызовы от API пользователей
- Ключевые категории логирования:
    - INFO логируем ключевые события
    - WARN логируем долгие операции (например расчет дольше 1 часа), подозрительная активность (много ошибок), нехватка ресурсов
    - DEBUG логируем детальные шаги для отладки

### MES API
INFO
- order_status_changed (old_status, new_status, order_id, operator_id)
- price_calculation_started, 
- price_calculation_finished (cost)
- order_assigned (operator_id, order_id)
ERROR
- price_calculation_failed
- database_connection_lost
- rabbitmq_connection_lost
- validation_failed
WARN
- cost_calculation_slow (expected_duration, actual_duration, polygons_cnt, order_id)
- high_memory_usage (mem_limit, mem_usage)
- rate_limit_exceeed (endpoint, req_limit, req_used, api_key_masked, client_ip)
DEBUG
- request_received
- message_published
- message_consumed
- external_call
- request_received

### CRM API:
INFO
- new_customer_reqistered
- order_status_changed (old_status, new_status, order_id, manager_id or job_name)
ERROR
- rabbitmq_connection_lost
- database_connection_lost
- validation_failed
WARN
- too_much_orders (orders_limit_in_process, real_orders_in_process)
- duplicated_order (order_id, similar_order_id)
DEBUG
- order_changed (old_data, new_data)

### Rabbit MQ
INFO
- new_queue
ERROR
- message_processing_failed
- too_much_messages
WARN
- slow_consumer
- high_memory_usage (mem_limit, mem_usage)
DEBUG
- message_published
- message_consumed

### Инфраструктурные логи:
- PostgreSQL: Ошибки, медленные запросы (>5s), deadlock-и. Не логировать полные запросы с параметрами в prod. (только при включенном флаге debug)
- RabbitMQ: Ошибки, предупреждения о нехватке ресурсов, сообщения в DLQ, события подключения/отключения клиентов
- S3-хранилище: Access-логи (запросы, ошибки доступа, объемы)

## Политика хранения
Структура индексов:
- mes-logs-2025.11.25 - горячий, 30 дней
- mes-logs-2025.11 - теплый, 90 дней
- mes-logs-2025 - холодный, 1 год
- mes-critical-errors - критические ошибки, хранение бессрочно

Горячий индекс треуется для оперативного анализа, считаем что за 30 дней заказ должен быть выполнен и 30 дневного хранения будет достаточно
- Горячий данные рекомендуется хранить на SSD диске для быстрого доступа, архив можно хранить на HDD

## Реагирование
Алерты:
- Количество логов ERROR на любом компоненте > 10 за 1 минуту: скачок ошибок
- Резкий рост заказов в статусе Создан: возможен риск DDOS атаки
- Количество логов WARN на любом компоненте > 10 за 1 минуту

## Безопасность
- В логах должны отсутствовать персональные данные в исходном виде (имя заказчика, номер телефона, почта), только идентификатор
- При необходимости логирования ПДН должны быть маскированы (например API ключ при логировании превышения rate лимита)
- Доступ к Jaeger, Jaeger UI, Grafana должен быть только изнутри контура компании и защищен корпоративной системой авторизации и аутентификации

## Выбор технологии
1. ELK + Filebeat
- filebeat на каждом поде, читает логи и отправляет данные
- logstash как процессинг логов
- elasticsearch как хранилище и поисковый движок
- kibana для визуализации
Плюсы:
- стандартное решение
- хороший поиск
- гибкость обработки

Минусы:
- тяжеловесность, много компонентов для настройки
- отдельные стеки (для логов ELK, для трейсов Jaeger, для метрик Prometeus)

2. OpenTelemetry подход
- otel agent отправляют логи и трейсы
- otel collector точка сбора данных и маршрутизации дальше
- можно отправить данные как в ELK, Loki и другие системы

Плюсы:
- общий формат для логов и трейсов
- otel уже запланировали использовать для трейсинга
- легко связать логи, трейсы, метрики

Минусы:
- меньше документации, молодое решение

3. Grafana stack (Loki, Prometeus, Tempo)
- Loki как Elastic для хранения
- Prometeus для метрик
- Tempo для трейсов

Плюсы:
- единый интерйес Grafana
Минусы:
- поиск хуже чем в Elastics

4. Splunk
Коробочное решение allinone
Плюсы:
- максимально простое в администрировании решение

Минусы:
- везде пишут, что стоит дороговато, но цену так и не удалось обнаружить
- виндорлок риск





